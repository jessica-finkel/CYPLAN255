{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b40ef5a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# CYPLAN255\n",
    "### Urban Informatics and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adc2c5d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "HIT RECORD and TRANSCRIBE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ceea7a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 12 -- APIs and Beyond <img src=\"https://i.imgur.com/HMHNjAq.jpg\" width=550 align='right' title=\"Scottish child actress, Binkie Stuart (1932 - 2001) hand in hand with a penguin during a visit to London Zoo, 15th April 1937. (Photo by Fox Photos/Hulton Archive/Getty Images)\">\n",
    "******\n",
    "March 7, 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f7d376",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Agenda\n",
    "1. Announcements\n",
    "2. Review: APIs + JSON\n",
    "2. Geocoding APIs\n",
    "3. The Census API\n",
    "4. Summary\n",
    "5. For next time\n",
    "6. Questions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1c0cef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5d336f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Assignment 4 (project proposal + initial analysis) due March 13\n",
    "- Final Project description released tonight\n",
    "- How far we've come"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10fb0c2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How Far We've Come\n",
    "\n",
    "1. ~Fundamentals of Programming~\n",
    "1. ~Intro to Data Analysis in Python~\n",
    "1. ~Intro to Data Visualization~\n",
    "1. APIs + Open Data\n",
    "1. Working with Geospatial Data\n",
    "1. Visualizing Spatial Data\n",
    "1. Statistical Analysis + Machine Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad29e96f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Review: APIs + JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3772037",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So far we've seen how you can use an API to download data stored as a .json file in some static location. That's cool, but ultimately not that different from clicking a link and downloading a file to your desktop. It also presumes you know the URL you want ahead of time, and that you want to download the entire file.\n",
    "\n",
    "Today we're going to be seeing how you can use APIs to interact with _services_, i.e. APIs that perform operations and generate the data you want on demand. To continue with the restaurant analogy, we started off ordering fast food burgers, but now we're ready for the tasting menu at Chez Panisse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a246c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"https://i.kym-cdn.com/photos/images/original/001/474/943/b12.jpg\" width=200 align=\"right\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53dc07",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "But before we get there, let's quickly review what we've learned so far by checking out the USGS real-time earthquake data API.\n",
    "\n",
    "### 2.1. USGS real-time earthquake feeds\n",
    "\n",
    "This is an API for near-real-time data about earthquakes. Data is provided in JSON format over the web. No authentication is needed, and there's no way to customize the output. Instead, the API has a separate endpoint for each permutation of the data that users might want.\n",
    "\n",
    "**API documentation:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/geojson.php\n",
    "\n",
    "**Sample API endpoint, for magnitude 4.5+ earthquakes in past day:**  \n",
    "http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_day.geojson  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbc4d57",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We'll start by querying the endpoint for magnitude 2.5+ quakes from the past week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce97c6f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json    \n",
    "import requests\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter\n",
    "\n",
    "endpoint_url = \"http://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/2.5_week.geojson\"\n",
    "response = requests.get(endpoint_url)\n",
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859d81a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It looks like the results are a string with JSON-formatted data inside, so we'll parse the string into a Python dictionary using `json.loads()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0bdfc5",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data = json.loads(response.text)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c199db8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since JSON is just a dictionary, we can access subsets of the data can with square brackets, using labels for the named elements in a key-value pair, and numerals for positional indexing of list items.\n",
    "\n",
    "Hint: whenever you see a file that ends in `.geojson`, you'll probably want to extract the data thats stored in the `features` dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639eda78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "quakes = data['features']\n",
    "quakes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "300de1ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Because it is a nested dictionary at this point, we can use indexing into the dictionary to extract results.  Recall our earlier use of nested dictionaries? This is why we learned how to navigate nested dictionaries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8309a3c8",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for q in quakes:\n",
    "    print(q['properties']['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb59435",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**SIDE BAR: GeoJSON?**\n",
    "\n",
    "Working with geospatial data over the web, you will inevitably encounter called GeoJSON. GeoJSON is just JSON (which is just...???) with a slightly more well-defined schema to distinguish between metadata, spatial features, and classes of spatial features (e.g. points vs. lines vs. polygons).\n",
    "\n",
    "There's lots of great tools out there for working with GeoJSON, but chief among them is [geojson.io](https://geojson.io). Try copying the first 5 entries from the quakes list into the `features` list on geojson.io and see what you find.\n",
    "\n",
    "HINT: it's a little bit tricker to go from Python to JSON than from JSON to Python because Python doesn't care about single-quotes vs. double quotes, but JavaScript does. You can use the `json.dumps()` method to convert a Python dictionary to a valid JSON string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75028def",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(json.dumps(response.json()['features'][:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a9b5d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Extracting data from nested dictionaries might be a good job for **list comprehension**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e388a8d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "d = {\n",
    "    'magnitude': [q['properties']['mag'] for q in quakes],\n",
    "    'depth': [q['geometry']['coordinates'][2] for q in quakes]\n",
    "}\n",
    "df = pd.DataFrame.from_dict(d)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fde900b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda945b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "df.plot(x='magnitude', y='depth', kind='scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87da7aa",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. Geocoding\n",
    "\n",
    "Now on to the main course: geocoding APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6d02f7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.1. What is geocoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba87c52",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Geocoding** describes the process of converting place names and addresses to geographic coordinates (e.g. lat/lon).\n",
    "\n",
    "JFF -- different levels of accuracy -- behind the scenes the geolocating is interpolating/guessing where between points it knows your address falls. Sometimes it will give you a sort of level of confidence behind how sure the geocoding tool is about the location. (need some fuzzy tolerance0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5deef415",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://dmpublisher.s3-us-west-2.amazonaws.com/old-dm/directionsmag.com/ee/images/newsletter/2004/10_20/EDramowicz_Figure1_lg.gif\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259467e7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Reverse geocoding is just the opposite process: using geographic coordinates to extract meaningful place names/addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9280e80b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Perhaps this sounds like a dull topic, but **geocoding is a fundamental tool for anyone wishing to do spatial data analysis**.\n",
    "\n",
    "Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b885400",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 9 times out of 10, your data will have _either_ geographic coordinates _or_ administrative boundary names, but not both!\n",
    "- 9 times out of 10 you will want to use additional data sources for which the above statement also applies\n",
    "- Geocoding allows you to translate between the two (e.g. merging Census data into Craiglist rental listings)\n",
    "\n",
    "#helps you align/join and combine data to have a more complete dataset since different datasets will use different variable names/data formats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bbfc6b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.2 Geocoding with the Mapbox API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657e7f0a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Services like Google Maps and Mapbox have various APIs that let you access its services through code instead of through GUI apps. This one from Mapbox lets you look up the latitude-longitude coordinates of street addresses. You'll need to create a Mapbox API token in order to use this API, which you can do by following the instructions [here ](https://www.mapbox.com/signin/?route-to=%22/account/access-tokens%22) if you have not alread done so."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d39ec89d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "The Mapbox API queries work just like the ones we've already seen, but now we're including our own query parameters in the URL endpoint!\n",
    "\n",
    "**API documentation:**  \n",
    "https://www.mapbox.com/api-documentation/#geocoding\n",
    "\n",
    "**API endpoint:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places\n",
    "\n",
    "**API endpoint with query parameters:**  \n",
    "https://api.mapbox.com/geocoding/v5/mapbox.places/Wurster+Hall.json?access_token=pk.eyJ1IjoiY3AyNTVkZW1vIiwiYSI6ImRPcTlnTUEifQ.3C0d0Nk_rcwV-8JF29PU-w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271a9d1d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.1. A word about API keys, tokens, and passwords in general\n",
    "\n",
    "It's never a good idea to print an API key in a public document, including a script or notebook like this one. Particularly when you're using Git, deleting private data after you've already committed the change won't remove the data from your project history!\n",
    "\n",
    "Instead, its good practice to create a small .json file which you can read into Python without ever having to print its contents. In this case, let's use a text editor to create a file named **mapbox_api_key.json** and put it in the `data/` directory. It's contents should look like this:\n",
    "\n",
    "#open a text editor and create a data dictionary with \"key\" as the key and your token as a value. From jupyter notebook, you can do open \"text file\" too, and say .json at the end of the file name. \n",
    "\n",
    "```javascript\n",
    "{\"key\": \"<your API key here>\"}\n",
    "```\n",
    "\n",
    "Now we can read the API key from disk:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3983e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import json  \n",
    "with open(\"data/mapbox_api_key.json\", 'r') as f:  #with open is standard python syntax for opening any file in 1s and 0s. \n",
    "                                                  #to make a json file, just save it with the .json file extension (instead \n",
    "                                                  #of as .txt, for example)\n",
    "\n",
    "    key_file = f.read()   #f.read is the way to convert the file into meaningful readable objects. \n",
    "    \n",
    "my_api_key = json.loads(key_file)['key']    #update this code to work with whatever I do to create/save my token, otherwise\n",
    "#none of the code cells below will run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a8fd35",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.2. Constructing an API query\n",
    "Now we're ready to format our API request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c50703",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "base_url = 'https://api.mapbox.com/geocoding/v5/mapbox.places/'\n",
    "address = 'Wurster Hall'\n",
    "params = {\n",
    "    'limit': 1,  # just get the first record/feature\n",
    "    'access_token': my_api_key}\n",
    "\n",
    "url = requests.Request('GET', base_url + address + '.json', params=params).prepare().url   \n",
    "#using requests.Request and telling \n",
    "#it to do a get request. This is what happens behind request.get, \n",
    "#but using this lower level function let's us specify more parameters. \n",
    "#It also allows us to use the .prepare() method. This just gives us the \n",
    "#URL that we want. Takes base url, appends the address, and \n",
    "#then tells it to append the .json extension. There are certain characters that an http request doesn't recognize, like\n",
    "#white space, so .prepare() takes it and makes it a valid http request. \n",
    "\n",
    "#In the output, the %20 is the code for white space. The \"?\" is \n",
    "#how API distinguishes between endpoint and the API parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c426fff",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This looks a little more complicated than what we saw last class. The main reason for this is that we are now doing more than simply submitting a `GET` request to URL whose full endpoint we know in advance. Instead, we just know the base URL of our API, and are using strings and key-value pairs to format the rest of the endpoint. This is pretty straightforward with one exception: HTTP doesn't know how to handle white space `\" \"` and many other special characters. So we are relying on the `Request.prepare()` method to take our input data and format it into a string that can be understood by HTTP.\n",
    "\n",
    "You can try printing the url in the cell below to see what this formatted version of the URL looks like, but be careful because it will contain your API key!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ee415",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf32263",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.3. Making the request and parsing the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238b29f",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pprint import PrettyPrinter as pp\n",
    "response = requests.get(url)\n",
    "results = response.text\n",
    "data = json.loads(results)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3120d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Does anyone think they have what it takes to extract the coordinates from our API response data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7baaeaf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#to explore a dictionary, can do data.keys() to figure out what first set of keys are. That will tell you if you need to go \n",
    "#below initial level to get what you are looking for. \n",
    "#Could do, e.g., data['features'][0]['center'] to get the info on the coordinates without having to go one level below at geometry.\n",
    "\n",
    "##try making a function per below to pass in the name of a place and get the coordinates without all the extra data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a2d6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.5 Exercises\n",
    "\n",
    "1. Search for some other addresses or landmarks!\n",
    "2. Try storing your code as a function named `get_coords()` so that you need only supply a place name and your function will return the coordinates as list or tuple:\n",
    "   ```python\n",
    "    def get_coords(place_str):\n",
    "        \n",
    "        # do something with \"place_str\"\n",
    "        \n",
    "        return coords\n",
    "        \n",
    "   ```\n",
    "2. Take a look at the [API documentation](https://www.mapbox.com/api-documentation/#geocoding). Can you figure out how to retrieve other points of interest near Wurster Hall?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e13c48",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%html \n",
    "<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/2KnJ183quw14FCd3Lb3pqL?utm_source=generator\" width=\"30%\" height=\"80\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de44928",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2.4. The Mapbox SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6606781",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Mapbox also maintans its own Python package which makes it a little easier to execute HTTP requests against its API. You can find the documentation [here](https://mapbox-mapbox.readthedocs-hosted.com/en/latest/index.html)\n",
    "\n",
    "NOTE: the Mapbox Python API seems to be a bit buggy. In particular it doesn't seem to support Python > 3.9. If you encounter any issues trying to import modules from this library, the best thing to do is to roll back your Python version. From a terminal, you can do:\n",
    "\n",
    "```bash\n",
    "conda install python=3.9\n",
    "```\n",
    "\n",
    "and then restart your notebook kernel using the Kernel drop down menu in the menu panel above (or by typing `00` in rapid succession in command mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097a0332",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.4.1. Forward Geocoding\n",
    "\n",
    "Forward geocoding is the one we have looked at so far using an API endpoint.  It takes an address or a place name and returns the geographic coordinates of that location.  Let's look at it again using the Mapbox Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fb10b3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mapbox import Geocoder\n",
    "import os\n",
    "\n",
    "geocoder = Geocoder(access_token=my_api_key) #passing API key to geocoder object. This instantiates geocoder object, so after that\n",
    "#don't have to pass api key after that since it's built into the object (or something like that)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f6ff0d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "OK, now we can get to work on the geocoding... let's try geocoding Freehouse Restaurant, which is at 2700 Bancroft Way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb51d5df",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = geocoder.forward('2700 Bancroft Way, Berkeley, CA 94704', limit=1)\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e89944f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Another random address to geocode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dd11d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = geocoder.forward('120 East 13th Street, Manhattan, New York, New York 10003', limit = 1)\n",
    "first = response.json()['features'][0]\n",
    "print(first['place_name'])\n",
    "print([coord for coord in first['geometry']['coordinates']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43744d5c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.4.2 Creating a dataframe from multiple API queries\n",
    "\n",
    "Can you think of a good way to write a loop to geocode those addresses and add them to a dataframe?  Let's try one way to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f0a178",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(index=[],columns=['address','lat','lon'])\n",
    "\n",
    "addrs = [\n",
    "    '3028 Regent St., Berkeley, California, 94705',\n",
    "    '1511 Julia St, Berkeley, California, 94703',\n",
    "    '2700 Bancroft, Berkeley, California, 94704']\n",
    "\n",
    "\n",
    "#this is one way to do multiple addresses at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa68d5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(addrs)):\n",
    "    geoadress=geocoder.forward(addrs[i], limit = 1).geojson()['features'][0]['geometry']['coordinates']\n",
    "    data.loc[i, 'address']=addrs[i]\n",
    "    data.loc[i, 'lon']=geoadress[0]\n",
    "    data.loc[i, 'lat']=geoadress[1]\n",
    "data\n",
    "\n",
    "#saying for each item in the dataframe, pass the address through the geocoder, give me the first feature as a geojson, \n",
    "#and give me the coordinates. For i in range(len(addrs)) --> says for each item in the range, which is 3 because I \n",
    "#have 3 addresses, #give me these things. So looping through my addresses and getting the \n",
    "#info that I want. Merging the inputs and the outputs into a dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85b6a8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.2.4.3 Reverse Geocoding\n",
    "\n",
    "Reverse geocoding does what it sounds like. It takes coordinates and returns an address or other place type.  Options for place type include: country, region, postcode, district, place, locality, neighborhood, address,and poi.\n",
    "\n",
    "Let's start by using the coordinates of the address we just got from forward geocoding, and get the address back from reverse geocoding of those coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d555f15d",
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = geocoder.reverse(lat=37.868965, lon=-122.254267) #in this case these are coordinates we got out of geocoding, so \n",
    "#we can be pretty sure it's accurate. But reverse geocoding can be less accurate since multiple things/places can be associated \n",
    "#with a latitude/longitude\n",
    "features = response.geojson()['features']\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48542758",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "for f in features:\n",
    "    print('{place_type[0]}'.format(**f) + ':', '{place_name}'.format(**f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6cd031",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bonus Section: Getting Directions from Mapbox\n",
    "\n",
    "You can put in start and end locations and call the Mapbox directions API to get suggested directions as a sequence of coordinates you could plot on a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#work through this on our own to see how the directions API from Mapbox works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b9fba",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from mapbox import Directions\n",
    "help(Directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fafa210",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "service = Directions()\n",
    "\n",
    "origin = {\n",
    "        'type': 'Feature',\n",
    "        'properties': {'name': 'Portland, OR'},\n",
    "        'geometry': {\n",
    "        'type': 'Point',\n",
    "        'coordinates': [-122.7282, 45.5801]}}\n",
    "destination = {\n",
    "    'type': 'Feature',\n",
    "    'properties': {'name': 'Bend, OR'},\n",
    "    'geometry': {\n",
    "    'type': 'Point',\n",
    "    'coordinates': [-121.3153, 44.0582]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726b01d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "response = service.directions([origin, destination],'mapbox/driving')\n",
    "driving_routes = response.geojson()\n",
    "driving_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d6957b",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "\n",
    "<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/2KnJ183quw14FCd3Lb3pqL?utm_source=generator\" width=\"30%\" height=\"80\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0b7ee5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.3 Geocoding with Nominatim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45a7cb3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Open source rules! Nominatim is an open source geocoding platform that is managed by OpenStreetMap (I think). Try using the Nominatim API to geocode or reverse geocode some data of interest! You can find the Nominamtim docs [here]. (https://nominatim.org/release-docs/develop/api/Search/)\n",
    "\n",
    "JFF -- It has its own API endpoint and own syntax for passing parameters through it. Doesn't require an API key since its open source, but they have some kind of limit on how many things you can do/request. \n",
    "\n",
    "Hint: whenever you're using an API for the first time, its always a good idea to start by trying to find some example queries in the documentation, and then tweaking them to meet your needs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed67a1c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/1392699734.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mquery_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'wurster hall'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://nominatim.openstreetmap.org/?addressdetails=1&q={0}&format=json&limit=1\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "query_str = 'wurster hall'\n",
    "url = \"https://nominatim.openstreetmap.org/?addressdetails=1&q={0}&format=json&limit=1\".format(query_str)\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36adc79",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/1535127487.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'res' is not defined"
     ]
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a8b5b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3.4 Exercise - Reverse geocoding with the FCC's API\n",
    "\n",
    "FCC's API is helpful for getting FIPS codes from addresses/latitude-longitude data. \n",
    "\n",
    "Let's load the Craigslist rental listings again and quickly clean it up using the same code we previously used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8bfae96",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>beds_sqft</th>\n",
       "      <th>pid</th>\n",
       "      <th>longitude</th>\n",
       "      <th>subregion</th>\n",
       "      <th>link</th>\n",
       "      <th>latitude</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>year</th>\n",
       "      <th>sqft</th>\n",
       "      <th>bedrooms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bayview</td>\n",
       "      <td>Take A TOUR ON OUR ONE FURNISHED BEDROOM TODAY</td>\n",
       "      <td>950.0</td>\n",
       "      <td>/ 1br -</td>\n",
       "      <td>4076905111</td>\n",
       "      <td>-122.396965</td>\n",
       "      <td>SF</td>\n",
       "      <td>/sfc/apa/4076905111.html</td>\n",
       "      <td>37.761216</td>\n",
       "      <td>Sep</td>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bayview</td>\n",
       "      <td>Only walking distance to major shopping centers.</td>\n",
       "      <td>950.0</td>\n",
       "      <td>/ 1br -</td>\n",
       "      <td>4076901755</td>\n",
       "      <td>-122.396793</td>\n",
       "      <td>SF</td>\n",
       "      <td>/sfc/apa/4076901755.html</td>\n",
       "      <td>37.761080</td>\n",
       "      <td>Sep</td>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bayview</td>\n",
       "      <td>furnished - 1 Bedroom(s), 1 Bath(s), Air Condi...</td>\n",
       "      <td>950.0</td>\n",
       "      <td>/ 1br -</td>\n",
       "      <td>4076899340</td>\n",
       "      <td>-122.397100</td>\n",
       "      <td>SF</td>\n",
       "      <td>/sfc/apa/4076899340.html</td>\n",
       "      <td>37.762100</td>\n",
       "      <td>Sep</td>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>financial district</td>\n",
       "      <td>*NEW* Beautiful, Upscale Condo in Historic Jac...</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>/ 1br - 830ft² -</td>\n",
       "      <td>4067393707</td>\n",
       "      <td>-122.399747</td>\n",
       "      <td>SF</td>\n",
       "      <td>/sfc/apa/4067393707.html</td>\n",
       "      <td>37.798108</td>\n",
       "      <td>Sep</td>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>830.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>visitacion valley</td>\n",
       "      <td>楼上全层3房</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>/ 3br - 1280ft² -</td>\n",
       "      <td>4076901071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SF</td>\n",
       "      <td>/sfc/apa/4076901071.html</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sep</td>\n",
       "      <td>18</td>\n",
       "      <td>2013</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         neighborhood                                              title  \\\n",
       "0             bayview     Take A TOUR ON OUR ONE FURNISHED BEDROOM TODAY   \n",
       "1             bayview   Only walking distance to major shopping centers.   \n",
       "2             bayview  furnished - 1 Bedroom(s), 1 Bath(s), Air Condi...   \n",
       "3  financial district  *NEW* Beautiful, Upscale Condo in Historic Jac...   \n",
       "4   visitacion valley                                             楼上全层3房   \n",
       "\n",
       "    price                 beds_sqft         pid   longitude subregion  \\\n",
       "0   950.0               / 1br -      4076905111 -122.396965        SF   \n",
       "1   950.0               / 1br -      4076901755 -122.396793        SF   \n",
       "2   950.0               / 1br -      4076899340 -122.397100        SF   \n",
       "3  3300.0      / 1br - 830ft² -      4067393707 -122.399747        SF   \n",
       "4  2000.0     / 3br - 1280ft² -      4076901071         NaN        SF   \n",
       "\n",
       "                       link   latitude month  day  year    sqft  bedrooms  \n",
       "0  /sfc/apa/4076905111.html  37.761216   Sep   18  2013     NaN       1.0  \n",
       "1  /sfc/apa/4076901755.html  37.761080   Sep   18  2013     NaN       1.0  \n",
       "2  /sfc/apa/4076899340.html  37.762100   Sep   18  2013     NaN       1.0  \n",
       "3  /sfc/apa/4067393707.html  37.798108   Sep   18  2013   830.0       1.0  \n",
       "4  /sfc/apa/4076901071.html        NaN   Sep   18  2013  1280.0       3.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('data/bay.csv')\n",
    "\n",
    "# clean price and neighborhood\n",
    "df.price = df.price.str.strip('$').astype('float64')\n",
    "df.neighborhood = df.neighborhood.str.strip().str.strip('(').str.strip(')')\n",
    "\n",
    "# break out the date into month day year columns\n",
    "df['month'] = df['date'].str.split().str[0]\n",
    "df['day'] = df['date'].str.split().str[1].astype('int32')\n",
    "df['year'] = df['date'].str.split().str[2].astype('int32')\n",
    "del df['date']\n",
    "\n",
    "# extract bedrooms and square footage\n",
    "def clean_bdrm(value):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        end = value.find('br')\n",
    "\n",
    "        if end == -1:\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            start = value.find('/') + 2\n",
    "            return int(value[start:end])\n",
    "\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "def clean_sqft(value):\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        end = value.find('ft')\n",
    "        \n",
    "        if end == -1:\n",
    "            return\n",
    "\n",
    "        else:\n",
    "            if value.find('br') == -1:\n",
    "                start = value.find('/') + 2\n",
    "            else:\n",
    "                start = value.find('-') + 2\n",
    "\n",
    "            return int(value[start:end])\n",
    "\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "df['sqft'] = df['beds_sqft'].map(clean_sqft)\n",
    "df['bedrooms'] = df['beds_sqft'].map(clean_bdrm)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c72b5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And now let's use the FCC [Census Block Conversions API](https://geo.fcc.gov/api/census/) to turn lat/long into a block FIPS code. FIPS codes contain from left to right: the location's 2-digit state code, 3-digit county code, 6-digit census tract code, and 4-digit census block code (the first digit of which is the census block group code). With a FIPS code in hand, you can easily merge your data against Census records. \n",
    "\n",
    "JFF -- in a previous notebook he had already done the steps below to include the long/lat data, but this shows us how he did it behind the scenes so we can do it ourselves. FCC doesn't require an API key, so free and anyone can use it, but don't abuse it and act like a bot and send hundreds of requests in a couple minutes. They might freeze us out by blocking IP address. But at home, practice forming URL queries on just a couple rows at a time for these rental listings. Don't keep testing the code on the entire dataset. Might want to print the row you are processing, maybe every 10th row to avoid getting an error at the end after it takes forever to process so you don't have to start all over. Do that using some conditional code that says something like \"if the request fails, then go on to the next record, else continue\". \n",
    "\n",
    "Here's a sample API query to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "805365c5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/2876972509.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mlon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m82.630303\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://geo.fcc.gov/api/census/block/find?latitude={0}&longitude={1}&format=json'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "lat = 34.537094\n",
    "lon = -82.630303\n",
    "url = 'https://geo.fcc.gov/api/census/block/find?latitude={0}&longitude={1}&format=json'.format(lat, lon)\n",
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0991d5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Your job now is to write some Python code to get the FIPS code for every row in the Craigslist rental data, and store that FIPS code as a new column in the dataframe. You might consider using [`df.iterrows()`](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.iterrows.html) to loop through each row of the dataframe one at a time, or if you're feeling fancy, you could define a function and use a vectorized approach (e.g. `df.apply()` or `df.map()`) to run the function on each row of your dataframe without any loops at all!\n",
    "\n",
    "**CAUTION: PLEASE DO NOT RUN THIS IN CLASS!!!** If we are all doing this at the same time on the same internet connection, you might get our IP address blacklisted by querying the API too many times.\n",
    "\n",
    "A few tips:\n",
    "- Since the API is SLOW for processing a lot of records, and works one record at a time, test out your code using only a few records until you are positive you have it working correctly. It may take several minutes to grind through all the records. You might want to print the row you are processing...maybe every 10th row, to give you some sense of how it is progressing.\n",
    "- Watch out for those missing lat-longs. You'll probably want to skip them since the API won't know what to do with them.\n",
    "- Consider adding some conditional logic to handle failed HTTP requests. This will prevent you from having to start your iteration over every time your program encounters an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f8e3d6",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/5kqMiwRHsewDj42jxMJSeW?utm_source=generator\" width=\"40%\" height=\"80\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad383a9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 4. The Census API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca598514",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Whatever \"Urban Informatics\" is or isn't, more often than not you'll find it useful to refer to census data. In this course, we'll be looking at capital-C Census data, i.e. the US Census, if for no other reason than the fact that it is being taught at UC Berkeley which happens to be located in California which happens to be located in the United States. Also, US Census data rocks!\n",
    "\n",
    "**Question**: Does anyone know of other countries that have good, publically available census data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a3b588",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The US Census provides API endpoints for most of its public data. You can find a list of them, along with links to their documentation, [here](https://www.census.gov/data/developers/data-sets.html). \n",
    "\n",
    "JFF -- all of the surveys have their own APIs and therefore their own APIs endpoints. Below we are looking at the 5-year ACS data. \n",
    "\n",
    "You can use those endpoints to construct your own custom queries and get the data you want by sending HTTP requests to those URLs. For example, to get the total population from 2018 in Alameda County, you can do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab593bfe",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/2629934747.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# execute the HTTP request\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# define parameters of our API query\n",
    "acs_var = 'B01001_001E'  # total pop\n",
    "state = '06'  # CA\n",
    "counties = ['001', '075']  # Alameda and SF\n",
    "year = 2018 #2018 5-year data\n",
    "\n",
    "# format the URL\n",
    "counties_str = ','.join(counties)\n",
    "url = \"https://api.census.gov/data/{0}/acs/acs5?get={1}&for=county:{2}&in=state:{3}\".format(\n",
    "    year, acs_var, counties_str, state)\n",
    "\n",
    "# execute the HTTP request\n",
    "res = requests.get(url)\n",
    "pd.DataFrame(res.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be829190",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.1. Getting a Census API key\n",
    "A word of warning. These Census API queries may or may not work for you without specifying an API key. It's probably a good idea to get one anyways, because you will eventually be asked for it after enough queries. You can do that [here](https://api.census.gov/data/key_signup.html)\n",
    "\n",
    "JFF -- not always needed for Census API, but sometimes you may need an API key, so a good idea to get one. The docs explain how."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5a351",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.2. Census API Python Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f857814f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One of the great things about working with open source software and open data is that people are publishing useful tools all the time that you can use to make your life easier. In the case of Census data, there are multiple Python libraries to choose from which are designed to make it a little easier to interact with the Census API.\n",
    "\n",
    "We'll focus on one that's simply called [census](https://github.com/datamade/census). You _will_ need a Census API key to use this package.\n",
    "\n",
    "Use the instructions on that GitHub repo to use `pip` to install the `census` package, along with its sister package `us`.\n",
    "\n",
    "JFF -- install the census package. pip install vs. conda install:\n",
    "Anaconda and Conda are relatively new on python scene. Before that there was pip to do package installs in python. It still exists, and in many cases certain libraries are only published on pip and not conda. So some packages may not be install-able in conda. So conda and pip are just different repositories of python packages. Some packages available on both, some only on one or the other. Import pip, which then lets you use other python libraries. Something about \"conda install pip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "048d754e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'census'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/1827722641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcensus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mCensus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Max stores his API key stored as an environment variable rather than a .json file. An environment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#variable is an alternative to storing it as a flat .json file like before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'census'"
     ]
    }
   ],
   "source": [
    "from census import Census\n",
    "from us import states\n",
    "\n",
    "# Max stores his API key stored as an environment variable rather than a .json file. An environment \n",
    "#variable is an alternative to storing it as a flat .json file like before. \n",
    "\n",
    "census_key = os.getenv(\"CENSUS_API\")  \n",
    "\n",
    "c = Census(census_key, year=year)\n",
    "res = c.acs5.get((\n",
    "    'NAME', acs_var), {\n",
    "    'for': 'county:{}'.format(counties_str),\n",
    "    'in': 'state:{}'.format(states.CA.fips)\n",
    "})\n",
    "\n",
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f513e7c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Census' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/2728981828.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0myear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2010\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2018\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCensus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcensus_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myear\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     res = c.acs1.get((\n\u001b[0;32m      6\u001b[0m         \u001b[1;34m'NAME'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macs_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Census' is not defined"
     ]
    }
   ],
   "source": [
    "acs_df = pd.DataFrame()\n",
    "\n",
    "for year in range(2010, 2018):\n",
    "    c = Census(census_key, year=year)\n",
    "    res = c.acs1.get((\n",
    "        'NAME', acs_var), {\n",
    "        'for': 'county:{}'.format(counties_str),\n",
    "        'in': 'state:{}'.format(states.CA.fips)\n",
    "    })\n",
    "\n",
    "    year_df = pd.DataFrame(res)\n",
    "    year_df['year'] = year\n",
    "    acs_df = pd.concat((acs_df, year_df), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcc9df3",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `year` for parameter `x`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14168/335467196.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlineplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macs_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0macs_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#plots the census data. If wanted to, could merge the census data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#and the rental data and plot that to see if there are correlations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m             )\n\u001b[0;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36mlineplot\u001b[1;34m(x, y, hue, size, style, data, palette, hue_order, hue_norm, sizes, size_order, size_norm, dashes, markers, style_order, units, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m     \u001b[0mvariables\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_LinePlotter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_semantics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 692\u001b[1;33m     p = _LinePlotter(\n\u001b[0m\u001b[0;32m    693\u001b[0m         \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mci\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mci\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_boot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\relational.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables, estimator, ci, n_boot, seed, sort, err_style, err_kws, legend)\u001b[0m\n\u001b[0;32m    365\u001b[0m         )\n\u001b[0;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    603\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 605\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_semantic_mappings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36massign_variables\u001b[1;34m(self, data, variables)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_format\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"long\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m             plot_data, variables = self._assign_variables_longform(\n\u001b[0m\u001b[0;32m    669\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\seaborn\\_core.py\u001b[0m in \u001b[0;36m_assign_variables_longform\u001b[1;34m(self, data, **kwargs)\u001b[0m\n\u001b[0;32m    901\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m                 \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"Could not interpret value `{val}` for parameter `{key}`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 903\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    904\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    905\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Could not interpret value `year` for parameter `x`"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.lineplot(data=acs_df, x='year', y=acs_var, hue='NAME') \n",
    "#plots the census data. If wanted to, could merge the census data \n",
    "#and the rental data and plot that to see if there are correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88d443c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4.3 More exercises!\n",
    "\n",
    "Your turn: \n",
    "1. Look up the latitude and longitude of your home address using forward geocoding\n",
    "2. Use the latitude and longitude from that to get the census block of your home address\n",
    "3. Challenge problem: create a dataframe with 3 street addresses and a description column with labels for these locations, and write code that will iterate through them, get the latitude and longitude for each, and the FIPS block code, County name, and write these addresses, lat and long, and FIPS Block code and County names to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517f72ab",
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe style=\"border-radius:12px\" src=\"https://open.spotify.com/embed/track/4KBULZasCMBDKHY8IPUCML?utm_source=generator\" width=\"40%\" height=\"80\" frameBorder=\"0\" allowfullscreen=\"\" allow=\"autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture\"></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f12f3e9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 5. Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97045cea",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "By this point in the class you have all the tools you need to:\n",
    "1. find interesting data sets\n",
    "1. load them into Python\n",
    "1. explore, clean, and manipulate that data\n",
    "1. combine it with external administrative or demographic data from the Census\n",
    "1. create charts and visualizations to communicate your findings\n",
    "1. save your new data to disk so you can come back to it later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c7bd9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 6. For next time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8626c722",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- We're about to enter my favorite module of this course: **Working with Geospatial Data**. Some of you have considerable experience with GIS already, and are very comfortable with concepts like coordinate reference systems and map projections, and how to deal with these when working with spatial data.  If so, you might not need to spend much time with the readings for next session, but if not, please at least familiarize yourself with the material from the first two links on the syllabus:\n",
    "  - [mapschool.io](https://mapschool.io/)\n",
    "  - Part I of [Geographic Data Science with Python](https://geographicdata.science/book/notebooks/00_toc.html)\n",
    "\n",
    "- We will also be using the GeoPandas Python library, so browse the documentation [here](http://geopandas.org/) and install it ahead of time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea0b2f7",
   "metadata": {
    "hide_input": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 7. Questions?"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "757px",
    "left": "31px",
    "top": "142.133px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
